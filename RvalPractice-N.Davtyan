---
title: "UntitledRvalPractice3"
author: "Nare Davtyan"
date: "3/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


install.packages("tidyverse",
                  "validate", "validatetools",
                  "errorlocate", "dcmodify", "simputation",
                  "DataExplorer", "funModeling",
                  "tseries", "forecast", "tsfeatures", 
                  "devtools" , "arules", "EditImputeCont", 
                  "vsgoftest", "factoextra", "cluster",
                  "caret", "tidymodels", 
                 dependencies=TRUE)

install.packages("knitr") 
install.packages("ggplot2") 
install.packages("DT") 
install.packages("rmarkdown")

df <- iris[,1:4]
# find optimal number of clusters
dff <- scale(df)
factoextra::fviz_nbclust(dff, kmeans, method = "gap_stat")
# compute and visualise
set.seed(123)
  km.res <- kmeans(dff, 3, nstart = 25)
# visualize
install.packages("factoextra")
library(factoextra)

factoextra::fviz_cluster(km.res, data = dff,
                         ellipse.type = "convex",
                         palette = "jco",
                         repel = TRUE,
                         ggtheme = ggplot2::theme_minimal())

pam.res <- cluster::pam(dff, 3)
# Visualize
factoextra::fviz_cluster(pam.res)

library(tseries)

tsuniv = ts(rnorm(1000))
rlist_univ <- list(
  tseries::jarque.bera.test(tsuniv),
  tseries::kpss.test(tsuniv),
  tseries::kpss.test(tsuniv, null = "Trend"),
  tseries::adf.test(tsuniv),
  forecast::Acf(tsuniv),
  forecast::Pacf(tsuniv),
  tsfeatures::tsfeatures(tsuniv)
)
rlist_univ

tsmultiv <- ts(matrix(rnorm(3000),ncol=100),freq=4)
# all important characteristics of multivar ts in:
all_characteristics <- tsfeatures::tsfeatures(tsmultiv)
all_characteristics



x <- c(1:30); y <- x^2+rnorm(30,0,2); model_ex = lm(y~x);
model_a <- model_ex

raintesting <- lmtest::raintest(model_a, order.by="mahalanobis")
print(raintesting)

durbin_watson_testing <- lmtest::dwtest(model_a)
hist(residuals(model_a))

jarque_bera_testing <- tseries::jarque.bera.test(residuals(model_a))
print(jarque_bera_testing)

 install.packages("vsgoftest")
library("vsgoftest")
vs_goodness_of_fit_testing <- vsgoftest::vs.test(x=residuals(model_a),
                                                 densfun="dnorm")
print(vs_goodness_of_fit_testing)


#portmanteau tests for model residuals, ts models
portmanteau_testing_ts_resid <- Box.test (residuals(model_a),
                                          lag = 1, type="Ljung")
print(portmanteau_testing_ts_resid)
# visualization, model diagnostics
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(model_a, las = 1)
# visualization, residuals diagnostics
lag.plot(residuals(model_a), lags=12, do.lines=FALSE)


kpss_testing <- tseries::kpss.test(residuals(model_a))
print(kpss_testing) #------- test of stationarity
adf_testing <- tseries::adf.test(residuals(model_a))
print(adf_testing) #-------- test of non-stationarity
#visualization: (auto-) correlation
par(mfrow=c(2,1))
# estimate of autocorr. fct, uni/multi-variate
acf(residuals(model_a))
# estimate of partial autocorr. fct, uni/multi-variate
pacf(residuals(model_a))


library(validate)
data(SBS2000)
original <- SBS2000
version2 <- original
# make a little change
version2$other.rev <- abs(version2$other.rev)
cells(input = original, cleaned = version2, compare="sequential")
# more versions of data
version3 <- version2
version3$turnover[is.na(version3$turnover)] <-
  version3$vat[is.na(version3$turnover)]

version4 <- version3
version4$turnover[is.na(version4$turnover)] <-
  median(version4$turnover, na.rm=TRUE)

# from kEUR to EUR
version5 <- version4
version5$staff.costs <- version5$staff.costs * 1000
# check comparisons by cell()
out <- cells(input = original
             , cleaned = version2
             , vat_imp = version3
             , med_imp = version4
             , units = version5)
par(mfrow=c(2,1))
barplot(out)
plot(out)

vrules <- validator(other.rev >= 0, turnover >= 0
                    , turnover + other.rev == total.rev)
comparison <- compare(vrules
                      , input = original, cleaned = version2
                      , vat_imp = version3, med_imp = version4
                      , units = version5)
comparison
par(mfrow=c(2,1))
barplot(comparison)
plot(comparison)

library(validate)
data(SBS2000)
original <- SBS2000
version2 <- original
# make a little change
version2$other.rev <- abs(version2$other.rev)
cells(input = original, cleaned = version2, compare="sequential")
# more versions of data
version3 <- version2
version3$turnover[is.na(version3$turnover)] <-
  version3$vat[is.na(version3$turnover)]


version4 <- version3
version4$turnover[is.na(version4$turnover)] <-
  median(version4$turnover, na.rm=TRUE)
# from kEUR to EUR
version5 <- version4
version5$staff.costs <- version5$staff.costs * 1000
# check comparisons by cell()
out <- cells(input = original
             , cleaned = version2
             , vat_imp = version3
             , med_imp = version4
             , units = version5)
par(mfrow=c(2,1))
barplot(out)
plot(out)



vrules <- validator(other.rev >= 0, turnover >= 0
                    , turnover + other.rev == total.rev)
comparison <- compare(vrules
                      , input = original, cleaned = version2
                      , vat_imp = version3, med_imp = version4
                      , units = version5)
comparison
par(mfrow=c(2,1))
barplot(comparison)
plot(comparison)


install.packages("dcmodify")
library(dcmodify)
m <- modifier(if (staff.costs < 0) staff.costs <- (-1) * staff.costs)
modified <- modify(retailers, m)
head(modified[3:7], 3)



library(errorlocate)
rules <- validator( profit == turnover - cost, cost >= 0.6 * turnover
                    , turnover >= 0, cost >= 0)
data <- data.frame(profit=750, cost=125, turnover=200)
error_locations <- locate_errors(data, rules)
values(error_locations)
summary(error_locations)
data_marked_errors <- replace_errors(data, rules)
# faulty data was replaced with NA
print(data_marked_errors)
er <- errors_removed(data_marked_errors)
print(er); summary(er); er$errors
sum(is.na(data))
sum(is.na(data_marked_errors))


library(simputation)
dat <- iris
dat[1:3,1] <- dat[3:7,2] <- dat[8:10,5] <- NA
head(dat,10)
da1 <- impute_lm(dat, Sepal.Length ~ Sepal.Width + Species)
head(da1,3)
da2 <- impute_median(da1, Sepal.Length ~ Species)
head(da2,3)
da3 <- impute_cart(da2, Species ~ .) #decision tree
head(da3,10)

install.packages("VIM")
install.packages("lumberjack")
install.packages("rspa")
install.packages("deductive")

df =datasets::iris #but any other is good
(citation("arules"))
library(arules)
tdata <- as(df, "transactions")
#method 1 of clustering: eclat algorithm
eclat_res <- inspect(eclat(tdata,
                           parameter = list(supp=0.07, maxlen=15)))
eclat_plot <- itemFrequencyPlot(tdata, topN=10,
                                type="absolute", main="item freguency")
summary_data <- summary(tdata)
eclat_summary <- summary(eclat(tdata,
                               parameter = list(supp=0.07, maxlen=15)))

#method 2 of clustering: apriori algorithm
rules <- apriori(tdata)
apriori_summary <- summary(rules)
apriori_res <- inspect(rules)

install.packages("EditImputeCont")

library(EditImputeCont)
## read the toy example data, which has two ratio edits and a balance edit
data(SimpleEx)
data1 = readData(Y.original=SimpleEx$D.obs, ratio=SimpleEx$Ratio.edit,
                 range=NULL, balance=SimpleEx$Balance.edit)
## create and initialize the model with 15 DP mixture components
model1 = createModel(data.obj=data1, K=15)
## Run an iteration of MCMC
model1$Iterate()
dim(model1$Y.edited)




















